{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import MSELoss, Module\n",
    "import spacy\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, batch_size):\n",
    "    \n",
    "    no_of_batches = len(data) // batch_size\n",
    "    \n",
    "    for n in range(0, len(data), no_of_batches):\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            x1 = data.sent_1.iloc[n:n + no_of_batches].values\n",
    "            x2 = data.sent_2.iloc[n:n + no_of_batches].values\n",
    "            Y = data.score.iloc[n:n + no_of_batches].values\n",
    "        \n",
    "        except IndexError:\n",
    "            \n",
    "            x1 = data.sent_1.iloc[n:].values\n",
    "            x2 = data.sent_2.iloc[n:].values\n",
    "            Y = data.score.iloc[n:].values\n",
    "    \n",
    "    yield x1, x2, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSimilarity():\n",
    "    \n",
    "    def __init__(self, tags_dict = None, correlation_matrix = None):\n",
    "        \n",
    "        self._tags = self._get_tags_dict() if tags_dict is None else tags_dict\n",
    "        self._no_of_tags = len(self._tags)\n",
    "#         TODO: initialize weights to identity, random, zeros\n",
    "        self._tag_correlation_matrix = np.identity(self._no_of_tags) if correlation_matrix is None else correlation_matrix\n",
    "        self._parser = spacy.load(\"en\")\n",
    "        \n",
    "    def _get_tags_dict(self):\n",
    "        \n",
    "        with open(\"data/tags.json\",\"r\") as fl:\n",
    "            tags = json.load(fl)\n",
    "            \n",
    "        return tags\n",
    "    \n",
    "    def _similarity_word(self, pair_A, pair_B):\n",
    "\n",
    "        #getting head and dependent texts \n",
    "        head_a, head_b = pair_A[0].text, pair_B[0].text\n",
    "        dep_a, dep_b = pair_A[2].text, pair_B[2].text\n",
    "\n",
    "        if head_a == head_b:\n",
    "            head = 1\n",
    "        else:\n",
    "            try:\n",
    "                #WordNet synsets for heads\n",
    "                head_a, head_b = wn.synsets(head_a)[0], wn.synsets(head_b)[0]\n",
    "                \n",
    "#                 TODO:Change similarity method\n",
    "                #path based similarity (Li et. al) for head\n",
    "                head = head_a.path_similarity(head_b)\n",
    "\n",
    "                head = 0 if head is None else head  \n",
    "\n",
    "            except Exception:\n",
    "                head = 0\n",
    "\n",
    "        if dep_a == dep_b:\n",
    "            dep = 1\n",
    "        else:\n",
    "            try:\n",
    "                #WordNet synsets for dependent\n",
    "                dep_a, dep_b = wn.synsets(dep_a)[0], wn.synsets(dep_b)[0]\n",
    "                \n",
    "#                 TODO:Change similarity method\n",
    "                #path based similarity (Li et. al) for dependent\n",
    "                dep = dep_a.path_similarity(dep_b)\n",
    "\n",
    "                dep = 0 if dep is None else dep\n",
    "\n",
    "            except Exception:\n",
    "                dep = 0     \n",
    "\n",
    "        return head + dep\n",
    "\n",
    "    def _similarity_tag(self, tag_a, tag_b):\n",
    "        \n",
    "        tag_a_id, tag_b_id = self._tags[tag_a], self._tags[tag_b] \n",
    "        score = self._tag_correlation_matrix[tag_a_id,tag_b_id]\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def semantic_similarity(self, documents_1, documents_2):\n",
    "        \n",
    "        #checking the sizes of both documents\n",
    "        assert len(documents_1) == len(documents_2), \"Size of both lists should be same.\"\n",
    "        \n",
    "        #scores vector\n",
    "        scores = torch.zeros([len(documents_1),],dtype=torch.double)\n",
    "        \n",
    "        i = 0\n",
    "            \n",
    "        for document_1, document_2 in zip(documents_1,documents_2):\n",
    "            \n",
    "            #parsing documets using spaCy English language parser\n",
    "            tokens_1,tokens_2 = self._parser(document_1), self._parser(document_2)\n",
    "\n",
    "            #seperating dependency pairs and tags from tokens\n",
    "            pairs_1 = [(token.head,token.dep_,token) for token in tokens_1]\n",
    "            pairs_2 = [(token.head,token.dep_,token) for token in tokens_2]\n",
    "\n",
    "            score = 0\n",
    "\n",
    "            #calculating score \n",
    "            for pair_A in pairs_1:\n",
    "\n",
    "                for pair_B in pairs_2:\n",
    "\n",
    "                    score += self._similarity_word(pair_A, pair_B) * self._similarity_tag(pair_A[1], pair_B[1])\n",
    "\n",
    "            #averaging score \n",
    "            #score = score / (len(tokens_1) + len(tokens_2))\n",
    "            \n",
    "            score = torch.sigmoid(score)\n",
    "            \n",
    "            scores[i] += score\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "        return scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9943, 0.9945], dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = TextSimilarity()\n",
    "sim._tag_correlation_matrix = torch.from_numpy(sim._tag_correlation_matrix)\n",
    "sim._tag_correlation_matrix.requires_grad = True\n",
    "sent_1 = [\"he is boy\",\"it is dog\"]\n",
    "sent_2 = [\"he is girl\",\"it is cat\"]\n",
    "score = sim.semantic_similarity(sent_1,sent_2)\n",
    "print(score)\n",
    "sim._tag_correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12450200147407048\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0108, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.9990, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = MSELoss()\n",
    "optimizer = torch.optim.Adam([sim._tag_correlation_matrix], lr=0.001)\n",
    "target = torch.DoubleTensor([.8,.7])\n",
    "target.requires_grad = True\n",
    "loss_score = loss(score, target)\n",
    "print(loss_score.item())\n",
    "loss_score.backward()\n",
    "print(sim._tag_correlation_matrix.grad)\n",
    "optimizer.step()\n",
    "sim._tag_correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, model, epochs = 25, lr = 0.001, validation_thresh = 0.2, batch_size = 10, print_every = 5):\n",
    "    \n",
    "    model._tag_correlation_matrix = torch.from_numpy(model._tag_correlation_matrix)\n",
    "    model._tag_correlation_matrix.requires_grad = True\n",
    "    \n",
    "    criterion = MSELoss()\n",
    "    optimizer = torch.optim.Adam([model._tag_correlation_matrix], lr=lr)\n",
    "    \n",
    "    thresh = int(validation_thresh * len(data))\n",
    "    \n",
    "    train_data = data.iloc[:thresh]\n",
    "    valid_data = data.iloc[thresh:]\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    count = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        losses = []\n",
    "        \n",
    "        for x1, x2, Y in get_batches(train_data, batch_size):\n",
    "            \n",
    "            count += 1\n",
    "        \n",
    "            scores = model.semantic_similarity(x1, x2)\n",
    "            \n",
    "            Y = torch.DoubleTensor(Y)\n",
    "            \n",
    "            loss = criterion(scores, Y)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            if count % print_every == 0:\n",
    "                \n",
    "                train_losses.append(np.mean(losses))\n",
    "                losses = []\n",
    "                \n",
    "                for x1, x2, Y in get_batches(valid_data, batch_size):\n",
    "                    \n",
    "                    scores = model.semantic_similarity(x1, x2)\n",
    "                    \n",
    "                    Y = torch.DoubleTensor(Y)\n",
    "                    \n",
    "                    loss = criterion(scores, Y)\n",
    "\n",
    "                    losses.append(loss.item())\n",
    "                    \n",
    "                valid_losses.append(np.mean(losses))\n",
    "                \n",
    "                print(f\"{count} {epoch}/{epochs}\\ttraining loss:{train_losses[-1]}\\tvalididation loss:{valid_losses[-1]}\")\n",
    "    \n",
    "    return train_losses,valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>sent_1</th>\n",
       "      <th>sent_2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The problem likely will mean corrective change...</td>\n",
       "      <td>He said the problem needs to be corrected befo...</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The technology-laced Nasdaq Composite Index .I...</td>\n",
       "      <td>The broad Standard &amp; Poor's 500 Index .SPX inc...</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"It's a huge black eye,\" said publisher Arthur...</td>\n",
       "      <td>\"It's a huge black eye,\" Arthur Sulzberger, th...</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SEC Chairman William Donaldson said there is a...</td>\n",
       "      <td>\"I think there's a building confidence that th...</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Vivendi shares closed 1.9 percent at 15.80 eur...</td>\n",
       "      <td>In New York, Vivendi shares were 1.4 percent d...</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Myanmar's pro-democracy leader Aung San Suu Ky...</td>\n",
       "      <td>Myanmar's pro-democracy leader Aung San Suu Ky...</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Darren Dopp, a Spitzer spokesman, declined to ...</td>\n",
       "      <td>John Heine, a spokesman for the commission in ...</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Bremer said one initiative is to launch a US$7...</td>\n",
       "      <td>Bremer said he would launch a $70-million prog...</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>In afternoon trading in Europe, France's CAC-4...</td>\n",
       "      <td>In Europe, France's CAC-40 rose 1.3 percent, B...</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>He later learned that the incident was caused ...</td>\n",
       "      <td>He later found out the alarming incident had b...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0           0.0   \n",
       "1           1           1.0   \n",
       "2           2           2.0   \n",
       "3           3           3.0   \n",
       "4           4           4.0   \n",
       "5           5           5.0   \n",
       "6           6           6.0   \n",
       "7           7           7.0   \n",
       "8           8           8.0   \n",
       "9           9           9.0   \n",
       "\n",
       "                                              sent_1  \\\n",
       "0  The problem likely will mean corrective change...   \n",
       "1  The technology-laced Nasdaq Composite Index .I...   \n",
       "2  \"It's a huge black eye,\" said publisher Arthur...   \n",
       "3  SEC Chairman William Donaldson said there is a...   \n",
       "4  Vivendi shares closed 1.9 percent at 15.80 eur...   \n",
       "5  Myanmar's pro-democracy leader Aung San Suu Ky...   \n",
       "6  Darren Dopp, a Spitzer spokesman, declined to ...   \n",
       "7  Bremer said one initiative is to launch a US$7...   \n",
       "8  In afternoon trading in Europe, France's CAC-4...   \n",
       "9  He later learned that the incident was caused ...   \n",
       "\n",
       "                                              sent_2  score  \n",
       "0  He said the problem needs to be corrected befo...   0.88  \n",
       "1  The broad Standard & Poor's 500 Index .SPX inc...   0.16  \n",
       "2  \"It's a huge black eye,\" Arthur Sulzberger, th...   0.72  \n",
       "3  \"I think there's a building confidence that th...   0.68  \n",
       "4  In New York, Vivendi shares were 1.4 percent d...   0.28  \n",
       "5  Myanmar's pro-democracy leader Aung San Suu Ky...   0.92  \n",
       "6  John Heine, a spokesman for the commission in ...   0.28  \n",
       "7  Bremer said he would launch a $70-million prog...   0.72  \n",
       "8  In Europe, France's CAC-40 rose 1.3 percent, B...   0.40  \n",
       "9  He later found out the alarming incident had b...   1.00  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/STS_Data1213.csv\",index_col=None)\n",
    "data.score = data.score/5.0\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextSimilarity()\n",
    "thresh = int(0.8 * len(data))\n",
    "\n",
    "train_data = data.iloc[:thresh]\n",
    "test_data = data.iloc[thresh:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4/200\ttraining loss:0.15783744671054073\tvalididation loss:0.17372434650858132\n",
      "10 9/200\ttraining loss:0.15778586422124907\tvalididation loss:0.16812720797087055\n",
      "15 14/200\ttraining loss:0.1575725157812162\tvalididation loss:0.1623273993875429\n",
      "20 19/200\ttraining loss:0.1566082453650173\tvalididation loss:0.1560216944725809\n",
      "25 24/200\ttraining loss:0.15215995395450052\tvalididation loss:0.1494623673376299\n",
      "30 29/200\ttraining loss:0.13871893176631836\tvalididation loss:0.14828524251485067\n",
      "35 34/200\ttraining loss:0.1258178725722612\tvalididation loss:0.15135618999210748\n",
      "40 39/200\ttraining loss:0.11291896791796821\tvalididation loss:0.15502419756011396\n",
      "45 44/200\ttraining loss:0.10982735518368265\tvalididation loss:0.15668704774587988\n",
      "50 49/200\ttraining loss:0.08439459256154673\tvalididation loss:0.15199080337690085\n",
      "55 54/200\ttraining loss:0.06556488981037116\tvalididation loss:0.14687903424821075\n",
      "60 59/200\ttraining loss:0.06085313400822855\tvalididation loss:0.147698377809606\n",
      "65 64/200\ttraining loss:0.054517684155365106\tvalididation loss:0.15129050566119337\n",
      "70 69/200\ttraining loss:0.05001740436708996\tvalididation loss:0.14632313455936283\n",
      "75 74/200\ttraining loss:0.04721701467873024\tvalididation loss:0.1463604355628113\n",
      "80 79/200\ttraining loss:0.04025048581437209\tvalididation loss:0.14364047569533758\n",
      "85 84/200\ttraining loss:0.017450931127691287\tvalididation loss:0.13635595050508512\n",
      "90 89/200\ttraining loss:0.0018759929013899626\tvalididation loss:0.13322006243382853\n",
      "95 94/200\ttraining loss:0.004461804614315695\tvalididation loss:0.13510999651730476\n",
      "100 99/200\ttraining loss:0.0034762438097014564\tvalididation loss:0.13467939536230383\n",
      "105 104/200\ttraining loss:0.0014894144255408537\tvalididation loss:0.13481894667086108\n",
      "110 109/200\ttraining loss:0.0004979449923575681\tvalididation loss:0.13639410644475608\n",
      "115 114/200\ttraining loss:0.000514647715927094\tvalididation loss:0.13554619844897497\n",
      "120 119/200\ttraining loss:0.00046446691617809495\tvalididation loss:0.13441827646449697\n",
      "125 124/200\ttraining loss:0.00011122341751401547\tvalididation loss:0.13522821949431268\n",
      "130 129/200\ttraining loss:0.00011362769836291279\tvalididation loss:0.13533273037859175\n",
      "135 134/200\ttraining loss:8.93190914163344e-05\tvalididation loss:0.13513775545311832\n",
      "140 139/200\ttraining loss:1.7421366988205353e-05\tvalididation loss:0.13546461300651957\n",
      "145 144/200\ttraining loss:2.816091443173209e-05\tvalididation loss:0.13511451857895823\n",
      "150 149/200\ttraining loss:1.1554168046680444e-05\tvalididation loss:0.13507213297098383\n",
      "155 154/200\ttraining loss:1.0667577366147404e-05\tvalididation loss:0.13531813719120864\n",
      "160 159/200\ttraining loss:4.395160644445638e-06\tvalididation loss:0.13519878461107693\n",
      "165 164/200\ttraining loss:2.996465491931997e-06\tvalididation loss:0.13523159362946444\n",
      "170 169/200\ttraining loss:2.183501469544379e-06\tvalididation loss:0.13522942690433593\n",
      "175 174/200\ttraining loss:9.134049957507624e-07\tvalididation loss:0.13517229343297055\n",
      "180 179/200\ttraining loss:7.324766158806605e-07\tvalididation loss:0.13523356854029236\n",
      "185 184/200\ttraining loss:1.7089005672921017e-07\tvalididation loss:0.13522260548028212\n",
      "190 189/200\ttraining loss:3.227524039343937e-07\tvalididation loss:0.135209837705185\n",
      "195 194/200\ttraining loss:7.311675108750458e-08\tvalididation loss:0.13522429102214234\n",
      "200 199/200\ttraining loss:9.929652111846905e-08\tvalididation loss:0.13520395367858848\n"
     ]
    }
   ],
   "source": [
    "#TODO: change epoch, lr, batch_size\n",
    "epoch = 200\n",
    "lr = 0.01\n",
    "batch_size = 10\n",
    "\n",
    "train_losses,valid_losses = train(train_data, model, epochs=epoch, lr=lr, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.8383,  0.0000,  ..., -0.0891, -0.3589, -0.2802],\n",
       "        [ 0.0000,  0.0000,  1.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.5342,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.5591]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._tag_correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y = test_data.score\n",
    "scores = model.semantic_similarity(test_data.sent_1, test_data.sent_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x132f08978>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.plot(valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2553, dtype=torch.float64, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y = torch.DoubleTensor(test_Y.values)\n",
    "loss(scores,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
