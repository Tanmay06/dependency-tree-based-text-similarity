{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import MSELoss, Module\n",
    "import spacy\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, batch_size):\n",
    "    \n",
    "    no_of_batches = len(data) // batch_size\n",
    "    \n",
    "    for n in range(0, len(data), no_of_batches):\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            x1 = data.sent_1.iloc[n:n + no_of_batches].values\n",
    "            x2 = data.sent_2.iloc[n:n + no_of_batches].values\n",
    "            Y = data.score.iloc[n:n + no_of_batches].values\n",
    "        \n",
    "        except IndexError:\n",
    "            \n",
    "            x1 = data.sent_1.iloc[n:].values\n",
    "            x2 = data.sent_2.iloc[n:].values\n",
    "            Y = data.score.iloc[n:].values\n",
    "    \n",
    "    yield x1, x2, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSimilarity():\n",
    "    \n",
    "    def __init__(self, tags_dict = None, correlation_matrix = None):\n",
    "        \n",
    "        self._tags = self._get_tags_dict() if tags_dict is None else tags_dict\n",
    "        self._no_of_tags = len(self._tags) \n",
    "        self._tag_correlation_matrix = np.identity(self._no_of_tags) if correlation_matrix is None else correlation_matrix\n",
    "        self._parser = spacy.load(\"en\")\n",
    "        \n",
    "    def _get_tags_dict(self):\n",
    "        \n",
    "        with open(\"data/tags.json\",\"r\") as fl:\n",
    "            tags = json.load(fl)\n",
    "            \n",
    "        return tags\n",
    "    \n",
    "    def _similarity_word(self, pair_A, pair_B):\n",
    "\n",
    "        #getting head and dependent texts \n",
    "        head_a, head_b = pair_A[0].text, pair_B[0].text\n",
    "        dep_a, dep_b = pair_A[2].text, pair_B[2].text\n",
    "\n",
    "        if head_a == head_b:\n",
    "            head = 1\n",
    "        else:\n",
    "            try:\n",
    "                #WordNet synsets for heads\n",
    "                head_a, head_b = wn.synsets(head_a)[0], wn.synsets(head_b)[0]\n",
    "\n",
    "                #path based similarity (Li et. al) for head\n",
    "                head = head_a.path_similarity(head_b)\n",
    "\n",
    "                head = 0 if head is None else head  \n",
    "\n",
    "            except Exception:\n",
    "                head = 0\n",
    "\n",
    "        if dep_a == dep_b:\n",
    "            dep = 1\n",
    "        else:\n",
    "            try:\n",
    "                #WordNet synsets for dependent\n",
    "                dep_a, dep_b = wn.synsets(dep_a)[0], wn.synsets(dep_b)[0]\n",
    "\n",
    "                #path based similarity (Li et. al) for dependent\n",
    "                dep = dep_a.path_similarity(dep_b)\n",
    "\n",
    "                dep = 0 if dep is None else dep\n",
    "\n",
    "            except Exception:\n",
    "                dep = 0     \n",
    "\n",
    "        return head + dep\n",
    "\n",
    "    def _similarity_tag(self, tag_a, tag_b):\n",
    "        \n",
    "        tag_a_id, tag_b_id = self._tags[tag_a], self._tags[tag_b] \n",
    "        score = self._tag_correlation_matrix[tag_a_id,tag_b_id]\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def semantic_similarity(self, documents_1, documents_2):\n",
    "        \n",
    "        #checking the sizes of both documents\n",
    "        assert len(documents_1) == len(documents_2), \"Size of both lists should be same.\"\n",
    "        \n",
    "        #scores vector\n",
    "        scores = torch.zeros([len(documents_1),],dtype=torch.double)\n",
    "        \n",
    "        i = 0\n",
    "            \n",
    "        for document_1, document_2 in zip(documents_1,documents_2):\n",
    "            \n",
    "            #parsing documets using spaCy English language parser\n",
    "            tokens_1,tokens_2 = self._parser(document_1), self._parser(document_2)\n",
    "\n",
    "            #seperating dependency pairs and tags from tokens\n",
    "            pairs_1 = [(token.head,token.dep_,token) for token in tokens_1]\n",
    "            pairs_2 = [(token.head,token.dep_,token) for token in tokens_2]\n",
    "\n",
    "            score = 0\n",
    "\n",
    "            #calculating score \n",
    "            for pair_A in pairs_1:\n",
    "\n",
    "                for pair_B in pairs_2:\n",
    "\n",
    "                    score += self._similarity_word(pair_A, pair_B) * self._similarity_tag(pair_A[1], pair_B[1])\n",
    "\n",
    "            #averaging score \n",
    "            score = score / (len(tokens_1) + len(tokens_2))\n",
    "            \n",
    "            scores[i] += score\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "        return scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8611, 0.8667], dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = TextSimilarity()\n",
    "sim._tag_correlation_matrix = torch.from_numpy(sim._tag_correlation_matrix)\n",
    "sim._tag_correlation_matrix.requires_grad = True\n",
    "sent_1 = [\"he is boy\",\"it is dog\"]\n",
    "sent_2 = [\"he is girl\",\"it is cat\"]\n",
    "score = sim.semantic_similarity(sent_1,sent_2)\n",
    "print(score)\n",
    "sim._tag_correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03706790123456788\n",
      "tensor([[-0.1815,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0010, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = MSELoss()\n",
    "optimizer = torch.optim.Adam([sim._tag_correlation_matrix], lr=0.001)\n",
    "target = torch.DoubleTensor([1.,1.])\n",
    "target.requires_grad = True\n",
    "loss_score = loss(score, target)\n",
    "print(loss_score.item())\n",
    "loss_score.backward()\n",
    "print(sim._tag_correlation_matrix.grad)\n",
    "optimizer.step()\n",
    "sim._tag_correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, model, epochs = 25, lr = 0.001, validation_thresh = 0.2, batch_size = 10, print_every = 5):\n",
    "    \n",
    "    model._tag_correlation_matrix = torch.from_numpy(model._tag_correlation_matrix)\n",
    "    model._tag_correlation_matrix.requires_grad = True\n",
    "    \n",
    "    criterion = MSELoss()\n",
    "    optimizer = torch.optim.Adam([model._tag_correlation_matrix], lr=lr)\n",
    "    \n",
    "    thresh = int(validation_thresh * len(data))\n",
    "    \n",
    "    train_data = data.iloc[:thresh]\n",
    "    valid_data = data.iloc[thresh:]\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    count = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        losses = []\n",
    "        \n",
    "        for x1, x2, Y in get_batches(train_data, batch_size):\n",
    "            \n",
    "            count += 1\n",
    "        \n",
    "            scores = model.semantic_similarity(x1, x2)\n",
    "            \n",
    "            Y = torch.DoubleTensor(Y)\n",
    "            \n",
    "            loss = criterion(scores, Y)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            if count % print_every == 0:\n",
    "                \n",
    "                train_losses.append(np.mean(losses))\n",
    "                losses = []\n",
    "                \n",
    "                for x1, x2, Y in get_batches(valid_data, batch_size):\n",
    "                    \n",
    "                    scores = model.semantic_similarity(x1, x2)\n",
    "                    \n",
    "                    Y = torch.DoubleTensor(Y)\n",
    "                    \n",
    "                    loss = criterion(scores, Y)\n",
    "\n",
    "                    losses.append(loss.item())\n",
    "                    \n",
    "                valid_losses.append(np.mean(losses))\n",
    "                \n",
    "                print(f\"{count} {epoch}/{epochs}\\ttraining loss:{train_losses[-1]}\\tvalididation loss:{valid_losses[-1]}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sent_1</th>\n",
       "      <th>sent_2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A person is on a baseball team.</td>\n",
       "      <td>A person is playing basketball on a team.</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Our current vehicles will be in museums when e...</td>\n",
       "      <td>The car needs to some work</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A woman supervisor is instructing the male wor...</td>\n",
       "      <td>A woman is working as a nurse.</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A bike is next to a couple women.</td>\n",
       "      <td>A child next to a bike.</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The group is eating while taking in a breathta...</td>\n",
       "      <td>A group of people take a look at an unusual tree.</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>The boy is raising his hand.</td>\n",
       "      <td>The man is raising his hand.</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>A man with a gray beard is being shaved in fro...</td>\n",
       "      <td>A man with a beard is sitting in the grass.</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>The sky has very little to no clouds.</td>\n",
       "      <td>This Lady might be ready for Rock Climbing, or...</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>The young boy jumps barefoot outside in the fr...</td>\n",
       "      <td>The teen rode his bike around the people walki...</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>There are dogs in the forest.</td>\n",
       "      <td>The dogs are alone in the forest.</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             sent_1  \\\n",
       "0           0                    A person is on a baseball team.   \n",
       "1           1  Our current vehicles will be in museums when e...   \n",
       "2           2  A woman supervisor is instructing the male wor...   \n",
       "3           3                  A bike is next to a couple women.   \n",
       "4           4  The group is eating while taking in a breathta...   \n",
       "5           5                       The boy is raising his hand.   \n",
       "6           6  A man with a gray beard is being shaved in fro...   \n",
       "7           7              The sky has very little to no clouds.   \n",
       "8           8  The young boy jumps barefoot outside in the fr...   \n",
       "9           9                      There are dogs in the forest.   \n",
       "\n",
       "                                              sent_2  score  \n",
       "0          A person is playing basketball on a team.   0.48  \n",
       "1                         The car needs to some work   0.04  \n",
       "2                     A woman is working as a nurse.   0.20  \n",
       "3                            A child next to a bike.   0.40  \n",
       "4  A group of people take a look at an unusual tree.   0.44  \n",
       "5                       The man is raising his hand.   0.68  \n",
       "6        A man with a beard is sitting in the grass.   0.16  \n",
       "7  This Lady might be ready for Rock Climbing, or...   0.08  \n",
       "8  The teen rode his bike around the people walki...   0.08  \n",
       "9                  The dogs are alone in the forest.   0.80  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/STS_Data1517.csv\",index_col=None)\n",
    "data.score = data.score/5.0\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4/100\ttraining loss:2.461224354807738e-05\tvalididation loss:0.2241588594273475\n",
      "10 9/100\ttraining loss:4.3036682712990605e-05\tvalididation loss:0.22332589108632722\n",
      "15 14/100\ttraining loss:3.000415454124361e-05\tvalididation loss:0.22392657661364557\n",
      "20 19/100\ttraining loss:1.8752427263441735e-05\tvalididation loss:0.22351082363111444\n",
      "25 24/100\ttraining loss:1.068336720246657e-05\tvalididation loss:0.22377802355875315\n",
      "30 29/100\ttraining loss:4.9024025111325515e-06\tvalididation loss:0.2236402806558718\n",
      "35 34/100\ttraining loss:1.2794812079790486e-06\tvalididation loss:0.2236642307207423\n",
      "40 39/100\ttraining loss:1.0770455037841425e-08\tvalididation loss:0.22372834092981778\n",
      "45 44/100\ttraining loss:4.3649623507168723e-07\tvalididation loss:0.2236184704292814\n",
      "50 49/100\ttraining loss:8.722827001738869e-07\tvalididation loss:0.22372097877059233\n",
      "55 54/100\ttraining loss:4.3065828014219844e-07\tvalididation loss:0.2236695533216579\n",
      "60 59/100\ttraining loss:5.663328316958643e-09\tvalididation loss:0.22365971923018318\n",
      "65 64/100\ttraining loss:1.2540883187049402e-07\tvalididation loss:0.2237009486458265\n",
      "70 69/100\ttraining loss:1.0828517977114768e-07\tvalididation loss:0.22367302002379166\n",
      "75 74/100\ttraining loss:5.414344205453138e-12\tvalididation loss:0.2236678464333855\n",
      "80 79/100\ttraining loss:4.2309154821175025e-08\tvalididation loss:0.223687332347914\n",
      "85 84/100\ttraining loss:7.37809460125551e-09\tvalididation loss:0.22368140086576788\n",
      "90 89/100\ttraining loss:9.855446017709409e-09\tvalididation loss:0.2236721874824661\n",
      "95 94/100\ttraining loss:5.081166524214794e-09\tvalididation loss:0.22367772484739928\n",
      "100 99/100\ttraining loss:2.9135484438583718e-09\tvalididation loss:0.22368226107371422\n"
     ]
    }
   ],
   "source": [
    "model = TextSimilarity()\n",
    "thresh = int(0.8 * len(data))\n",
    "\n",
    "train_data = data.iloc[:thresh]\n",
    "test_data = data.iloc[thresh:]\n",
    "\n",
    "epoch = 100\n",
    "lr = 0.01\n",
    "train(train_data, model, epochs=epoch, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._tag_correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-250088f2061f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemantic_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-8a882509066d>\u001b[0m in \u001b[0;36msemantic_similarity\u001b[0;34m(self, documents_1, documents_2)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mpair_B\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs_2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_similarity_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_B\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_similarity_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_A\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_B\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m#averaging score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-8a882509066d>\u001b[0m in \u001b[0;36m_similarity_tag\u001b[0;34m(self, tag_a, tag_b)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_similarity_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mtag_a_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_b_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tag_correlation_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_a_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag_b_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "test_Y = test_data.score\n",
    "scores = model.semantic_similarity(test_data.sent_1, test_data.sent_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
